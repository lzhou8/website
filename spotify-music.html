<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Lillie Zhou</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
   <script src="https://kit.fontawesome.com/268b8bb572.js"></script>
   <script src="https://d3js.org/d3.v4.js" charset="utf-8"></script>
   <link rel="stylesheet" href="css/flight-delays/styles.css">
</head>

<body>
  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark static-top">
    <div class="container">
      <a class="navbar-brand" href="index.html">Lillie Zhou</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          
          <li class="nav-item">
            <a class="nav-link" href="about.html">About</a>
          </li>
          <li class="nav-item active">
            <a class="nav-link" href="projects.html">Projects</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <div class="card" style="margin-top: 50px; margin-bottom: 50px; margin-right: 100px; margin-left: 100px;">
  <div class="card-body">
    <h1>Spotify Audio Features: An Exploratory Data Analysis</h1>
    <h4><u>Introduction:</u></h4>
    <p>“Lofi”, or low fidelity, is a type of music that is characterized by its deliberate use of "production flaws", electic sounds, and interesting instrumentals. The lack of broader discussion on the Internet about this genre of music, as well as my recent discovery of Spotify’s developer APIs, inspired me to create some data visualizations to assess its audio features. 
    </p>

    <h4><u>Data:</u></h4>
    <p>I first wrote a Python utility that makes use of Spotipy (a Python library) to gain access to Spotify's web APIs. Each artist on Spotify is associated with a particular URI; I decided to use the URI for the artist, "Lofi Chillhop", due to the abundance of lofi-style music that this artist has released. Through some Python code, I was able to extract all the tracks from this artist's albums. Each track (along with its associated audio features) was subsequently written to a CSV file to build some data visualizations with.
    </p>

    <h4><u>Analysis:</u></h4>

    <p>This exploratory data analysis seeks to answer the primary question: <br>What generalizations can be made about the audio features that characterize this type of music?
    <br>
    <br>

    According to Spotify’s API documents, audio can be evaluated based on 8 quantitative features:<br>

    <b>Danceability</b>: <i>"Describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable."</i><br>

    <b>Instrumentalness:</b> <i>"Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content."</i><br>
    
    <b>Energy:</b> <i>"Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale."</i><br>

    <b>Liveness:</b> <i>"Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live."</i><br>

    <b>Loudness:</b> <i>"The overall loudness of a track in decibels (dB)."</i><br>

    <b>Speechiness:</b> <i>"Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value."</i><br>

    <b>Valence:</b> <i>"A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry)." </i><br>

    <b>Acousticness:</b> <i>"A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic."</i></p>


    <img src="img/music.png" height="400px" width="500px">
    <img src="img/music2.png" height="400px" width="500px">

    <br>
    <p>
    I created a box and whisker plot to analyze the median for 7 audio features. As observed, the Lofi songs in this dataset trend towards high acousticness, high danceability, low to mid energy, high instrumentality, low liveness, low speechiness, and low to mid valence. </p>


</div>
</body>
</html>